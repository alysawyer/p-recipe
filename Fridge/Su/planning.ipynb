{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/bengisubulur/Desktop/p-recipe/Fridge/Su/planning.ipynb Cell 1\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bengisubulur/Desktop/p-recipe/Fridge/Su/planning.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_LAUNCH_BLOCKING\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m1\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bengisubulur/Desktop/p-recipe/Fridge/Su/planning.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Import libraries\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/bengisubulur/Desktop/p-recipe/Fridge/Su/planning.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bengisubulur/Desktop/p-recipe/Fridge/Su/planning.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/bengisubulur/Desktop/p-recipe/Fridge/Su/planning.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Set up CUDA in OS\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import seaborn as sn \n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check version of Pytorch\n",
    "print(torch. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out if a GPU is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up path for data after downloading\n",
    "rain_dir = \"C:/Users/Kirudang/Desktop/Assignment 2/Skin cancer dataset/train/\"\n",
    "test_dir = \"C:/Users/Kirudang/Desktop/Assignment 2/Skin cancer dataset/test/\"\n",
    "train_classa_dir = \"C:/Users/Kirudang/Desktop/Assignment 2/Skin cancer dataset/train/benign/\"\n",
    "train_classb_dir = \"C:/Users/Kirudang/Desktop/Assignment 2/Skin cancer dataset/train/malignant/\"\n",
    "test_classa_dir = \"C:/Users/Kirudang/Desktop/Assignment 2/Skin cancer dataset/test/benign/\"\n",
    "test_classb_dir = \"C:/Users/Kirudang/Desktop/Assignment 2/Skin cancer dataset/test/malignant/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image for reference\n",
    "white_torch = torchvision.io.read_image('C:/Users/Kirudang/Desktop/Assignment 2/Skin cancer dataset/test/benign/1.jpg')\n",
    "print(\"This is benign skin cancer\")\n",
    "T.ToPILImage()(white_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image for reference\n",
    "wh = torchvision.io.read_image('C:/Users/Kirudang/Desktop/Assignment 2/Skin cancer dataset/test/benign/44.jpg')\n",
    "print(\"This is malignant skin cancer\")\n",
    "T.ToPILImage()(wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transform function\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   #must same as here\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(), # data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalization\n",
    "])\n",
    "transforms_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   #must same as here\n",
    "     transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply for training and test data\n",
    "train_dataset = datasets.ImageFolder(train_dir, transforms_train)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transforms_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=0)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=12, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train dataset size:', len(train_dataset))\n",
    "print('Test dataset size:', len(test_dataset))\n",
    "class_names = train_dataset.classes\n",
    "print('Class names:', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 60\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "def imshow(input, title):\n",
    "    # torch.Tensor => numpy\n",
    "    input = input.numpy().transpose((1, 2, 0))\n",
    "    # undo image normalization\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    input = std * input + mean\n",
    "    input = np.clip(input, 0, 1)\n",
    "    # display images\n",
    "    plt.imshow(input)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "# load a batch of train image\n",
    "iterator = iter(train_dataloader)\n",
    "# visualize a batch of train image\n",
    "inputs, classes = next(iterator)\n",
    "out = torchvision.utils.make_grid(inputs[:4])\n",
    "imshow(out, title=[class_names[x] for x in classes[:4]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
